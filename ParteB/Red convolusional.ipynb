{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importación de librerías"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from keras.utils import to_categorical\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from numpy.lib.npyio import savez_compressed\n",
    "#!/usr/bin/env python\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D, Dense, Flatten\n",
    "from keras.utils import normalize, to_categorical\n",
    "from IPython.display import display\n",
    "from sklearn.model_selection import train_test_split\n",
    "from random import uniform\n",
    "from scipy.sparse import random\n",
    "from numpy import random as np_random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#carga datos\n",
    "#data = pd.read_csv('lp5.csv', sep=',')\n",
    "from google.colab import files\n",
    "uploaded = files.upload()\n",
    "data = np.loadtxt('lp5.csv', delimiter=',',dtype=str)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Se separan las categorias y las matrices en listas separadas\n",
    "count = 0\n",
    "matriz = []\n",
    "label = []\n",
    "for i in range(2624): \n",
    "    if (count==0):\n",
    "        label.append((data[i]))\n",
    "    if (count > 0):\n",
    "        matriz.append((data[i]))\n",
    "    count+=1 \n",
    "    if (count == 16): \n",
    "      count = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#se anaden los valores a una matriz\n",
    "matriz_data=np.zeros((len(matriz), 6))\n",
    "\n",
    "for i in range(2460):\n",
    "    for j in range(6):\n",
    "        matriz_data[i][j] = float(matriz[i][j])\n",
    "display(matriz_data)\n",
    "\n",
    "#normalizar datos\n",
    "\n",
    "# utilizando metodo de min max\n",
    "valor_minimo = np.min(matriz_data)\n",
    "valor_maximo = np.max(matriz_data)\n",
    "matriz_data_Nor = matriz_data - valor_minimo\n",
    "matriz_data_Nor =matriz_data_Nor / (valor_maximo - valor_minimo)\n",
    "\n",
    "display (\"matriz de datos\", matriz_data_Nor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Se genera la matriz de 3 dimenciones necesaria para el modulo convolucional\n",
    "count = 0\n",
    "mat_final=np.zeros((164,15,6))\n",
    "for i in range(164): \n",
    "      for j in range(15):\n",
    "          for k in range(6):\n",
    "              mat_final[i][j][k] = matriz_data_Nor[count][k] \n",
    "          count += 1 \n",
    "\n",
    "mat_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Se genera la lista con la categorixacion de las labels.\n",
    "cat = pd.DataFrame(label, columns=['category', '1', '2', '3', '4', '5'])\n",
    "if any(cat['category'] == 'normal'):\n",
    "    cat.loc[cat['category'] == 'normal' ] = ['normal',1, 0, 0, 0, 0]\n",
    "if any(cat['category'] == 'collision_in_tool'):\n",
    "    cat.loc[cat['category'] == 'collision_in_tool' ] = ['collision_in_tool',0, 1, 0, 0, 0]\n",
    "if any(cat['category'] == 'collision_in_part'):\n",
    "    cat.loc[cat['category'] == 'collision_in_part' ] = ['collision_in_part', 0, 0, 1, 0, 0]\n",
    "if any(cat['category'] == 'bottom_collision'):\n",
    "    cat.loc[cat['category'] == 'bottom_collision' ] = ['bottom_collision',0, 0, 0, 1, 0]\n",
    "if any(cat['category'] == 'bottom_obstruction'):\n",
    "    cat.loc[cat['category'] == 'bottom_obstruction' ] = ['bottom_collision',0, 0, 0, 0, 1]\n",
    "clases_clasificacion1 =cat.drop(['category'], axis=1)\n",
    "clases_clasificacion= clases_clasificacion1.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Division de datos de entrenamiento\n",
    "X_train,X_test,y_train,y_test = train_test_split( mat_final, clases_clasificacion, test_size=0.4, random_state=42)\n",
    "X_train = np.array([np.array(val) for val in X_train])\n",
    "\n",
    "\n",
    "#Division de datos para validacion para validacion 1\n",
    "X_validacion,X_test,y_validacion,y_test = train_test_split( X_test, y_test, test_size=0.4, random_state=42)\n",
    "\n",
    "#obtencion de datos sinteticos para validacin 2\n",
    "display(np.shape(X_test))\n",
    "\n",
    "ruido_sintetico=np.zeros((27,15,6))\n",
    "for i in range(27): \n",
    "      for j in range(15):\n",
    "          for k in range(6):\n",
    "              b=np_random.uniform(-0.05,0.05)\n",
    "              ruido_sintetico[i][j][k] =X_test[i][j][k]+ ((X_test[i][j][k] )*b)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Capas del modelo convolucional\n",
    "activation = 'relu'\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, kernel_size=3, activation = activation, strides=(2, 1), input_shape=(15,6,1) ))\n",
    "\n",
    "model.add(Conv2D(64, kernel_size=3,strides=(1,1),  padding = 'same', activation = activation))\n",
    "model.add(MaxPooling2D())\n",
    "\n",
    "model.add(Conv2D(64, kernel_size=3,strides=(1, 1), padding = 'same', activation = activation )) \n",
    "model.add(MaxPooling2D())\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(16, activation = activation))\n",
    "model.add(Dense(5, activation = 'softmax'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Definicion del modelo y ejecucion de entrenamiento\n",
    "model.compile(optimizer = 'rmsprop',loss = 'categorical_crossentropy', metrics = ['accuracy'])\n",
    "history = model.fit(X_train, y_train, epochs=200, batch_size=4,validation_data =(X_test, y_test))\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "model.predict(ruido_sintetico)\n",
    "#predictions= model.predict(ruido_sintetico)\n",
    "#rounded_labels=np.argmax(predictions, axis=1)#\n",
    "#Y_real=np.argmax(y_test, axis=1)\n",
    "#cm = confusion_matrix(Y_real, rounded_labels)\n",
    "\n",
    "model.predict(X_validacion)\n",
    "#predictions= model.predict(X_validacion)\n",
    "#rounded_labels=np.argmax(predictions, axis=1)#\n",
    "#Y_real=np.argmax(y_test, axis=1)\n",
    "#cm = confusion_matrix(Y_real, rounded_labels)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
